{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from afinn import Afinn\n",
    "afinn=Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Data_reviews1_to_44_Final.xlsx')\n",
    "df['Review Date']=pd.to_datetime(df['Review Date'])\n",
    "df=df.sort_values('Review Date',ascending=False).reset_index()\n",
    "df=df.drop('index',axis=1)\n",
    "df.to_csv('forR.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=sorted(os.listdir('/Users/FrankLIUChangxuan/Desktop/Proj/quarter_rev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Overall topics\n",
    "def getTopicSentiment(file):\n",
    "    \n",
    "    d1=pd.read_csv('quarter_rev/'+file,index_col=0)\n",
    "    vectorizer1=CountVectorizer(stop_words='english')\n",
    "    X=vectorizer1.fit_transform(d1['Review'])\n",
    "    terms=vectorizer1.get_feature_names()\n",
    "    lda=LatentDirichletAllocation(n_components=5,learning_method='online').fit(X)\n",
    "    topics=[' '.join([terms[i] for i in topic.argsort()[:-5-1:-1]]) for topic_idx,topic in enumerate(lda.components_)]\n",
    "    mtx=[lda.fit_transform(X[k]) for k in range(X.shape[0])]\n",
    "    print(topics)\n",
    "\n",
    "    t0=[mtx[i][0][0] for i in range(len(mtx))]\n",
    "    t1=[mtx[i][0][1] for i in range(len(mtx))]\n",
    "    t2=[mtx[i][0][2] for i in range(len(mtx))]\n",
    "    t3=[mtx[i][0][3] for i in range(len(mtx))]\n",
    "    t4=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t5=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t6=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t7=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t8=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t9=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    \n",
    "    d1=pd.concat([d1,pd.DataFrame({'topic0':t0,'topic1':t1,'topic2':t2,'topic3':t3,'topic4':t4})],axis=1)\n",
    "    d1=d1.sort_values('Restaurant.name').drop([0])\n",
    "    \n",
    "    #sentiment\n",
    "    r_names=[]\n",
    "    shr=[]\n",
    "    time=[]\n",
    "    score_t0=[]\n",
    "    score_t1=[]\n",
    "    score_t2=[]\n",
    "    score_t3=[]\n",
    "    score_t4=[]\n",
    "    #score_t5=[]\n",
    "    #score_t6=[]\n",
    "    #score_t7=[]\n",
    "    #score_t8=[]\n",
    "    #score_t9=[]\n",
    "    for r_name in d1['Restaurant.name'].unique():\n",
    "        r_names.append(r_name)\n",
    "        time.append(int(file[4:8]+'0'+file[10]))\n",
    "        r=d1.loc[d1['Restaurant.name']==r_name]\n",
    "        shr.append(len(r.index)/len(d1.index))\n",
    "        score_t0.append(afinn.score(''.join([i for i in r.loc[r['topic0']>0.8]['Review']])))\n",
    "        score_t1.append(afinn.score(''.join([i for i in r.loc[r['topic1']>0.8]['Review']])))\n",
    "        score_t2.append(afinn.score(''.join([i for i in r.loc[r['topic2']>0.8]['Review']])))\n",
    "        score_t3.append(afinn.score(''.join([i for i in r.loc[r['topic3']>0.8]['Review']])))\n",
    "        score_t4.append(afinn.score(''.join([i for i in r.loc[r['topic4']>0.8]['Review']])))\n",
    "        #score_t5.append(afinn.score(''.join([i for i in r.loc[r['topic5']>0.8]['Review']])))\n",
    "        #score_t6.append(afinn.score(''.join([i for i in r.loc[r['topic6']>0.8]['Review']])))\n",
    "        #score_t7.append(afinn.score(''.join([i for i in r.loc[r['topic7']>0.8]['Review']])))\n",
    "        #score_t8.append(afinn.score(''.join([i for i in r.loc[r['topic8']>0.8]['Review']])))\n",
    "        #score_t9.append(afinn.score(''.join([i for i in r.loc[r['topic9']>0.8]['Review']])))\n",
    "    return pd.DataFrame({'mkt_shr':shr,\n",
    "                         'Restaurant.name':r_names,\n",
    "                         'Review.date':time,\n",
    "                         'score_t0':score_t0,'score_t1':score_t1,'score_t2':score_t2,'score_t3':score_t3,'score_t4':score_t4},\n",
    "                         #'score_t5':score_t5,'score_t6':score_t6,'score_t7':score_t7,'score_t8':score_t8,'score_t9':score_t9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kid changing vendor thoughtful daycare', 'experience food like new didn', 'taqueria 1st healthy ago burritos', 'rabbit attracted jacob conejo unpretentious', 'food good great place mexican', 'exceptionally subjected unacceptable pretentious condescending', 'perfume ruined 06 busser choked', 'paquitos juice sugar blue giant', 'lamb standard birria moose watch', 'taco tacos pork asada carne']\n",
      "['food good great place service', 'million cammorones caution sooooo fog칩n', 'delivery funny weird rock honest', 'barrio wallet lost mailed yes', 'enchilada umm chukkis remember half', 'radishes azul cake provide stand', 'service dog password cash sorry', 'tacos place carne asada taco', 'coconut tai mai called pecado', 'nachos steak antiguo rooftop casco']\n",
      "['incredible passion pm eveerything texmex', 'food place tacos great good', 'fellow vendetta losing rebellion cheerful', 'mazatl치n locos papa bistec chille', 'steak beuno pecado pit sounded', 'food good mexican place drinks', 'favor quick bite grinds assorted', 'beans food sauce good ordered', 'waffles migas powerful waffle premixed', 've food service seattle chips']\n",
      "['food place tacos good great', 'steak bathroom night gender bathrooms', 'shalt thou salsa grilled major', 'mug booth chilies mousse refills', 'pumpkin antonio soft unique san', 'chiles rellenos gigantic catching mojado', 'oaxaque침o boxing distance ole gestures', 'rude attitude walked brittany table', 'great sauce barely good lime', 'soy chorizo uber manager excuse']\n",
      "['item sopes substance substantial jerky', 'somewhat level surroundings medieval entrances', 'food place good tacos great', 'delivery hrs reservations passed memory', 'manhattan tucson plane ticket respect', 'jello wearing pollo fairly best', 'card lemon jar wrap movie', 'food stars dirty person bell', 'tamales coffee masa use fancy', 'gluten food free friendly staff']\n",
      "['flan agua frescas joaquin sorry', 'food horchata people portions mexican', 'tempted seeking establishments wa enjoyment', 'jose holder holders napkin neat', 'manager outside quite finally huevos', 'food place tacos good great', 'told minutes table asked party', 'tea 20 jaime food bar', 'downstairs selections connected pharmacy speakeasy', 'gracia ones clandestine station floor']\n",
      "['chips good salsa food delicious', 'fired windows dressing painful 16', 'quality ballard diego san food', 'dollars baby taco does mulitas', 'carne asada meat reservation ve', 'order know food maybe asked', '27 chief steep celebrate felix', 'food tacos place good great', 'years food flies good outstanding', 'blah gogogo tostados lish original']\n",
      "['waygu ate yummy said steak', 'event dancing break owner antiguo', 'mex tex steak wagyu new', 'hole wall thrilled read yelling', 'poquitos place baby asked winner', 'goat dessert masa diet middle', 'el cheese gum sirenito extra', 'wild roast chilli cafe peach', 'food good place great tacos', 'bottles spanish old pants forcefully']\n",
      "['wait table place delicious service', 'adventure hooked ghetto huevallos scenery', 'owner azul blah fresa luna', 'straws luna bike flying hole', 'breakfast just maria big churro', 'asked gravy sausage los togo', 'senor moose cafe crowds post', 'nachos despite concise distance shredded', 'food good tacos place great', 'casa patron brunch rancheros huevos']\n",
      "['food good tacos great place', 'fish watch bar guy mulita', 'bone isnt bag marrow wood', 'fog칩n bloody mary mezcaleria wonderful', 'forever paneer rule computer underwhelming', 'oz yell yelling weeknight red', 'music patio tofu choices art', 'empanada course cream popsicles mesa', 'sal story sit reservation painting', 'interesting foods relaxing styled earthy']\n",
      "['morning mud breakfast invented dolly', 'af virgin yam sopes including', 'alana gf christian sean box', 'travis refused en shitty thank', 'food mexican place good great', 'food good tacos great place', 'mezcaleria amigo buena dulce bananas', 'lovely getting money wonderfully balanced', 'tension girl experience returned wants', 'tacos taco chukis meat pineapple']\n",
      "['asked server right taco phone', 'dog los bag city hole', 'kids hungry leave sad cheese', 'kid staff given event beer', 'food good place tacos mexican', 'food service tacos great good', 'love chukis hr issues day', 'service like didn wanted said', 'cap breast arroz leche pozole', 'avocado dip offer queso churros']\n"
     ]
    }
   ],
   "source": [
    "dfs=[getTopicSentiment(x) for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names=[df['Restaurant.name'] for df in dfs]\n",
    "rst_always=set.intersection(*map(set,all_names))\n",
    "dfs=[df.loc[df['Restaurant.name'].isin(rst_always)] for df in dfs]\n",
    "final=pd.concat(dfs)\n",
    "final.to_csv('final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
