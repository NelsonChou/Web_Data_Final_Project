{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from afinn import Afinn\n",
    "afinn=Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Data_reviews1_to_44_Final.xlsx')\n",
    "df['Review Date']=pd.to_datetime(df['Review Date'])\n",
    "df=df.sort_values('Review Date',ascending=False).reset_index()\n",
    "df=df.drop('index',axis=1)\n",
    "df.to_csv('forR.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year2016_Q1.csv',\n",
       " 'Year2016_Q2.csv',\n",
       " 'Year2016_Q3.csv',\n",
       " 'Year2016_Q4.csv',\n",
       " 'Year2017_Q1.csv',\n",
       " 'Year2017_Q2.csv',\n",
       " 'Year2017_Q3.csv',\n",
       " 'Year2017_Q4.csv',\n",
       " 'Year2018_Q1.csv',\n",
       " 'Year2018_Q2.csv',\n",
       " 'Year2018_Q3.csv',\n",
       " 'Year2018_Q4.csv']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=sorted(os.listdir('/Users/FrankLIUChangxuan/Desktop/Proj/quarter_rev'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Overall topics\n",
    "def getTopicSentiment(file):\n",
    "    \n",
    "    d1=pd.read_csv('quarter_rev/'+file,index_col=0)\n",
    "    vectorizer1=CountVectorizer(ngram_range=(1,1),min_df=1,stop_words='english')\n",
    "    X=vectorizer1.fit_transform(d1['Review'])\n",
    "    terms=vectorizer1.get_feature_names()\n",
    "    lda=LatentDirichletAllocation(n_components=5,learning_method='online').fit(X)\n",
    "    topics=[' '.join([terms[i] for i in topic.argsort()[:-5-1:-1]]) for topic_idx,topic in enumerate(lda.components_)]\n",
    "    mtx=[lda.fit_transform(X[k]) for k in range(X.shape[0])]\n",
    "    print(topics)\n",
    "\n",
    "    t0=[mtx[i][0][0] for i in range(len(mtx))]\n",
    "    t1=[mtx[i][0][1] for i in range(len(mtx))]\n",
    "    t2=[mtx[i][0][2] for i in range(len(mtx))]\n",
    "    t3=[mtx[i][0][3] for i in range(len(mtx))]\n",
    "    t4=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t5=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t6=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t7=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t8=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    #t9=[mtx[i][0][4] for i in range(len(mtx))]\n",
    "    \n",
    "    d1=pd.concat([d1,pd.DataFrame({'topic0':t0,'topic1':t1,'topic2':t2,'topic3':t3,'topic4':t4})],axis=1)\n",
    "    d1=d1.sort_values('Restaurant.name').drop([0])\n",
    "    \n",
    "    #sentiment\n",
    "    r_names=[]\n",
    "    shr=[]\n",
    "    time=[]\n",
    "    score_t0=[]\n",
    "    score_t1=[]\n",
    "    score_t2=[]\n",
    "    score_t3=[]\n",
    "    score_t4=[]\n",
    "    #score_t5=[]\n",
    "    #score_t6=[]\n",
    "    #score_t7=[]\n",
    "    #score_t8=[]\n",
    "    #score_t9=[]\n",
    "    rating=[]\n",
    "    for r_name in d1['Restaurant.name'].unique():\n",
    "        r_names.append(r_name)\n",
    "        time.append(int(file[4:8]+'0'+file[10]))\n",
    "        r=d1.loc[d1['Restaurant.name']==r_name]\n",
    "        shr.append(len(r.index)/len(d1.index))\n",
    "        score_t0.append(afinn.score(''.join([i for i in r.loc[r['topic0']>0.8]['Review']])))\n",
    "        score_t1.append(afinn.score(''.join([i for i in r.loc[r['topic1']>0.8]['Review']])))\n",
    "        score_t2.append(afinn.score(''.join([i for i in r.loc[r['topic2']>0.8]['Review']])))\n",
    "        score_t3.append(afinn.score(''.join([i for i in r.loc[r['topic3']>0.8]['Review']])))\n",
    "        score_t4.append(afinn.score(''.join([i for i in r.loc[r['topic4']>0.8]['Review']])))\n",
    "        #score_t5.append(afinn.score(''.join([i for i in r.loc[r['topic5']>0.8]['Review']])))\n",
    "        #score_t6.append(afinn.score(''.join([i for i in r.loc[r['topic6']>0.8]['Review']])))\n",
    "        #score_t7.append(afinn.score(''.join([i for i in r.loc[r['topic7']>0.8]['Review']])))\n",
    "        #score_t8.append(afinn.score(''.join([i for i in r.loc[r['topic8']>0.8]['Review']])))\n",
    "        #score_t9.append(afinn.score(''.join([i for i in r.loc[r['topic9']>0.8]['Review']])))\n",
    "        rating.append(np.mean([i for i in r['Rating']]))\n",
    "    return pd.DataFrame({'mkt_shr':shr,\n",
    "                         'Restaurant.name':r_names,\n",
    "                         'Review.date':time,\n",
    "                         'score_t0':score_t0,'score_t1':score_t1,'score_t2':score_t2,'score_t3':score_t3,'score_t4':score_t4,\n",
    "                         'Rating':rating})\n",
    "                         #'score_t5':score_t5,'score_t6':score_t6,'score_t7':score_t7,'score_t8':score_t8,'score_t9':score_t9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food good great place salsa', 'tacos taco food place mexican', 'tacoma approached crusted servers sorry', 'good really food salsa place', 'enchilada breakfast dairy taqueria manager']\n",
      "['food good tacos place mexican', 'got good food happy bar', 'password man cash soup counter', 'radishes music wallet barrio yes', 'happening bad food just beach']\n",
      "['tacos taco meat asada like', 'food good place great tacos', 'later source details toilet unbelievable', 'pregnant lady tops boys asking', 'lo coffee scene believe dude']\n",
      "['tacos food place good asada', 'price lunch hole portion extremely', 'delivery consistent bitesquad nogada chiles', 'food table service good just', 'food great good place mexican']\n",
      "['gluten free given beef er', 'food place good tacos great', 'item sopes substance substantial recommendation', 'hopes lemon delivery menus wearing', 'blah business closing open food']\n",
      "['downstairs flatbread pharmacy chicharrones connected', 'mezcal flan ordered cactus server', 'jaime business nadia event thank', 'food tacos place good great', 'food service time table just']\n",
      "['cut life san diego hair', 'food good place great mexican', 'tacos food place taco good', 'carbon ridiculously alright continue fundido', 'potato slushy blanco used supporting']\n",
      "['asked said manager gum extra', 'happy feed hour spiced mash', 'food good place great tacos', 'brunch texas compliments ribeyes nuff', 'lil oxacan roast chilli bright']\n",
      "['asked straws maria server gravy', 'food good place tacos great', 'garibaldi plaza 45 los eat24', 'taco restaurant like food asado', 'uber clue sorry write rico']\n",
      "['interesting foods cactus earthy styled', 'food good tacos great place', 'food just like good really', 'burrito empanada cream course mesa', 'copal wood oven joke radishes']\n",
      "['rats jesus beacon balanced getting', 'moose se√±or cat af empire', 'food tacos good place great', '00 website information closed arrived', 'rainy bouncer gordito fans suggestions']\n",
      "['tortilla soup chips reservation make', 'bacon kids mushroom pitcher greens', 'family calories healthy pounding issues', 'love team casa flight chukis', 'food good tacos place great']\n"
     ]
    }
   ],
   "source": [
    "dfs=[getTopicSentiment(x) for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names=[df['Restaurant.name'] for df in dfs]\n",
    "rst_always=set.intersection(*map(set,all_names))\n",
    "dfs=[df.loc[df['Restaurant.name'].isin(rst_always)] for df in dfs]\n",
    "final=pd.concat(dfs)\n",
    "final.to_csv('final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
